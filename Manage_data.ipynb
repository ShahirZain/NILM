{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redd Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_appliance = {\n",
    "    'microwave': {\n",
    "        'windowlength': 599,\n",
    "        'on_power_threshold': 200,\n",
    "        'max_on_power': 3969,\n",
    "        'mean': 500,\n",
    "        'std': 800,\n",
    "        's2s_length': 128,\n",
    "        'houses': [1, 2, 3],\n",
    "        'channels': [11, 6, 16],\n",
    "        'train_build': [2, 3],\n",
    "        'test_build': 1\n",
    "    },\n",
    "    'fridge': {\n",
    "        'windowlength': 599,\n",
    "        'on_power_threshold': 50,\n",
    "        'max_on_power': 3323,\n",
    "        'mean': 200,\n",
    "        'std': 400,\n",
    "        's2s_length': 512,\n",
    "        'houses': [1, 2, 3],\n",
    "        'channels': [5,9,7],\n",
    "        'train_build': [2, 3],\n",
    "        'test_build': 1\n",
    "    },\n",
    "    'dishwasher': {\n",
    "        'windowlength': 599,\n",
    "        'on_power_threshold': 10,\n",
    "        'max_on_power': 3964,\n",
    "        'mean': 700,\n",
    "        'std': 1000,\n",
    "        's2s_length': 1536,\n",
    "        'houses': [1, 2, 3],\n",
    "        'channels': [6, 10, 9],\n",
    "        'train_build': [2, 3],\n",
    "        'test_build': 1\n",
    "    },\n",
    "    'washingmachine': {\n",
    "        'windowlength': 599,\n",
    "        'on_power_threshold': 20,\n",
    "        'max_on_power': 3999,\n",
    "        'mean': 400,\n",
    "        'std': 700,\n",
    "        's2s_length': 2000,\n",
    "        'houses': [1, 2, 3],\n",
    "        'channels': [19, 7, 13],\n",
    "        'train_build': [2, 3],\n",
    "        'test_build': 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY='./REDD_DataSet/low_freq'\n",
    "SAVE_PATH = './normalized_data/'\n",
    "AGG_MEAN = 522\n",
    "AGG_STD = 814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=easydict.EasyDict({\n",
    "    \"data_dir\":DATA_DIRECTORY,\n",
    "    \"appliance_name\":'fridge',\n",
    "    \"aggregate_mean\":AGG_MEAN,\n",
    "    \"aggregate_std\":AGG_STD,\n",
    "    \"save_path\":SAVE_PATH\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fridge\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# args = get_arguments()\n",
    "appliance_name = args.appliance_name\n",
    "print(appliance_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fridge\n",
      "    ./REDD_DataSet/low_freq house_1/channel_5.dat\n",
      "    Size of test set is 0.1971 M rows.\n",
      "    ./REDD_DataSet/low_freq house_2/channel_9.dat\n",
      "    ./REDD_DataSet/low_freq house_3/channel_7.dat\n",
      "    Size of total training set is 0.3004 M rows.\n",
      "    Size of total validation set is 0.0334 M rows.\n",
      "\n",
      "Please find files in: ./normalized_data/\n",
      "Total elapsed time: 87.98 min.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    sample_seconds = 8\n",
    "    validation_percent = 10\n",
    "    nrows = None\n",
    "    debug = False\n",
    "\n",
    "    appliance_name = args.appliance_name\n",
    "    print('\\n' + appliance_name)\n",
    "    train = pd.DataFrame(columns=['aggregate', appliance_name])\n",
    "    \n",
    "\n",
    "    for h in params_appliance[appliance_name]['houses']:\n",
    "        print('    ' + args.data_dir + ' house_' + str(h) + '/'\n",
    "                + 'channel_' +\n",
    "                str(params_appliance[appliance_name]['channels'][params_appliance[appliance_name]['houses'].index(h)]) +\n",
    "                '.dat')\n",
    "                                    # read data\n",
    "    #reading mains 1 data from redd house 1\n",
    "        mains1_df = pd.read_table(args.data_dir + '/' + 'house_' + str(h) + '/' + 'channel_' + \n",
    "                                      str(1) + '.dat',\n",
    "                                      sep=\"\\s+\",\n",
    "                                      nrows=nrows,\n",
    "                                      usecols=[0, 1],\n",
    "                                      names=['time', 'mains1'],\n",
    "                                      dtype={'time': str},\n",
    "                                      )\n",
    "    #reading mains 2 data from redd house 1\n",
    "        mains2_df = pd.read_table(args.data_dir + '/' + 'house_' + str(h) + '/' + 'channel_' +\n",
    "                                      str(2) + '.dat',\n",
    "                                      sep=\"\\s+\",\n",
    "                                      nrows=nrows,\n",
    "                                      usecols=[0, 1],\n",
    "                                      names=['time', 'mains2'],\n",
    "                                      dtype={'time': str},\n",
    "                                      )\n",
    "    #reading Appliance data from redd for house 1\n",
    "        app_df = pd.read_table(args.data_dir + '/' + 'house_' + str(h) + '/' + 'channel_' +\n",
    "                                   str(params_appliance[appliance_name]['channels']\n",
    "                                       [params_appliance[appliance_name]['houses'].index(h)]) + '.dat',\n",
    "                                   sep=\"\\s+\",\n",
    "                                   nrows=nrows,\n",
    "                                   usecols=[0, 1],\n",
    "                                   names=['time', appliance_name],\n",
    "                                   dtype={'time': str},\n",
    "                                   )\n",
    "        mains1_df['time'] = pd.to_datetime(mains1_df['time'], unit='s')\n",
    "        mains2_df['time'] = pd.to_datetime(mains2_df['time'], unit='s')\n",
    "\n",
    "        mains1_df.set_index('time', inplace=True)\n",
    "        mains2_df.set_index('time', inplace=True)\n",
    "        mains_df = mains1_df.join(mains2_df, how='outer')\n",
    "\n",
    "        mains_df['aggregate'] = mains_df.iloc[:].sum(axis=1)\n",
    "        mains_df.reset_index(inplace=True)\n",
    "        del mains_df['mains1'], mains_df['mains2']\n",
    "\n",
    "        if debug:\n",
    "            print(\"    mains_df:\")\n",
    "            print(mains_df.head())\n",
    "            plt.plot(mains_df['time'], mains_df['aggregate'])\n",
    "            plt.show()\n",
    "\n",
    "            # Appliance\n",
    "            # app_df = app_df.set_index(app_df.columns[0])\n",
    "            # app_df.index = pd.to_datetime(app_df.index, unit='s')\n",
    "        app_df['time'] = pd.to_datetime(app_df['time'], unit='s')\n",
    "            # app_df.columns = [appliance_name]\n",
    "        if debug:\n",
    "            print(\"app_df:\")\n",
    "            print(app_df.head())\n",
    "            plt.plot(app_df['time'], app_df[appliance_name])\n",
    "            plt.show()\n",
    "\n",
    "            # the timestamps of mains and appliance are not the same, we need to align them\n",
    "            # 1. join the aggragte and appliance dataframes;\n",
    "            # 2. interpolate the missing values;\n",
    "        mains_df.set_index('time', inplace=True)\n",
    "        app_df.set_index('time', inplace=True)\n",
    "\n",
    "        df_align = mains_df.join(app_df, how='outer'). \\\n",
    "                resample(str(sample_seconds) + 'S').mean().fillna(method='backfill', limit=1)\n",
    "        df_align = df_align.dropna()\n",
    "\n",
    "        df_align.reset_index(inplace=True)\n",
    "            #print(df_align.count())\n",
    "            # df_align['OVER 5 MINS'] = (df_align['time'].diff()).dt.seconds > 9\n",
    "            # df_align.plot()\n",
    "            # plt.plot(df_align['OVER 5 MINS'])\n",
    "            # plt.show()\n",
    "\n",
    "        del mains1_df, mains2_df, mains_df, app_df, df_align['time']\n",
    "\n",
    "        mains = df_align['aggregate'].values\n",
    "        app_data = df_align[appliance_name].values\n",
    "            # plt.plot(np.arange(0, len(mains)), mains, app_data)\n",
    "            # plt.show()\n",
    "\n",
    "        if debug:\n",
    "                # plot the dtaset\n",
    "            print(\"df_align:\")\n",
    "            print(df_align.head())\n",
    "            plt.plot(df_align['aggregate'].values)\n",
    "            plt.plot(df_align[appliance_name].values)\n",
    "            plt.show()\n",
    "         # Normilization\n",
    "        mean = params_appliance[appliance_name]['mean']\n",
    "        std = params_appliance[appliance_name]['std']\n",
    "\n",
    "        df_align['aggregate'] = (df_align['aggregate'] - args.aggregate_mean) / args.aggregate_std\n",
    "        df_align[appliance_name] = (df_align[appliance_name] - mean) / std\n",
    "\n",
    "        if h == params_appliance[appliance_name]['test_build']:\n",
    "            # Test CSV\n",
    "            df_align.to_csv(args.save_path + appliance_name + '_test_.csv', mode='a', index=False, header=False)\n",
    "            print(\"    Size of test set is {:.4f} M rows.\".format(len(df_align) / 10 ** 6))\n",
    "            continue\n",
    "\n",
    "\n",
    "        train = train.append(df_align, ignore_index=True)\n",
    "        del df_align\n",
    "\n",
    "        # Validation CSV\n",
    "    val_len = int((len(train)/100)*validation_percent)\n",
    "    val = train.tail(val_len)\n",
    "    val.reset_index(drop=True, inplace=True)\n",
    "    train.drop(train.index[-val_len:], inplace=True)\n",
    "    val.to_csv(args.save_path + appliance_name + '_validation_' + '.csv', mode='a', index=False, header=False)\n",
    "\n",
    "        # Training CSV\n",
    "    train.to_csv(args.save_path + appliance_name + '_training_.csv', mode='a', index=False, header=False)\n",
    "\n",
    "    print(\"    Size of total training set is {:.4f} M rows.\".format(len(train) / 10 ** 6))\n",
    "    print(\"    Size of total validation set is {:.4f} M rows.\".format(len(val) / 10 ** 6))\n",
    "    del train, val\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nPlease find files in: \" + args.save_path)\n",
    "    #tot = int(int(time.time() - start_time) / 60)\n",
    "    print(\"Total elapsed time: {:.2f} min.\".format((time.time() - start_time) / 60))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
